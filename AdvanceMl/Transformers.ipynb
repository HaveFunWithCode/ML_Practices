{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29783d6",
   "metadata": {},
   "source": [
    "# Feature Transformation and Scaling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4636d898",
   "metadata": {},
   "source": [
    "---------------------------------------------------concept----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41c41bc1",
   "metadata": {},
   "source": [
    "Sometimes our datasets have different columns with different value scales. for example, one column's value range is from 0 to 1000 and another column is from 0 to 1! So model do not treats both features(columns) equally! Actually column with larger value can influence more the result of model. we can prevent this problem by feature scaling.\n",
    "there are a lot of scaling method. you should choose based on your data.\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b29492ab",
   "metadata": {},
   "source": [
    "---------------------------------------------------implementation---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a54a15",
   "metadata": {},
   "source": [
    "<b>StandardScaler</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f53f4",
   "metadata": {},
   "source": [
    "the Standard Scaler scales the values in a way the mean would be 0 and the STD would be  1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185db53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8bb020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44b85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(housing.data,housing.target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7a09f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   3.6125       15.            5.91780822 ...    2.84931507\n",
      "    38.53       -120.59      ]\n",
      " [   4.8173       22.            5.53623188 ...    2.90144928\n",
      "    38.15       -121.74      ]\n",
      " [   4.4423       37.            5.68435013 ...    2.77718833\n",
      "    33.84       -118.12      ]\n",
      " ...\n",
      " [   1.4639        6.            3.6898263  ...    3.74441687\n",
      "    34.         -118.29      ]\n",
      " [   2.4375       12.            3.96173733 ...    2.33505688\n",
      "    34.2        -118.48      ]\n",
      " [  13.8093        7.            6.51724138 ...    2.89655172\n",
      "    37.31       -122.11      ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8730b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean is : [   3.8626996    28.55087209    5.4382726     1.0983114  1424.96947674\n",
      "    3.08010931   35.6347356  -119.56775055]\n",
      "STD is : [   1.87758414   12.5984457     2.40242197    0.47692123 1128.80065849\n",
      "   11.3510555     2.13827971    2.004983  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"the mean is : {}\".format(X_train.mean(axis=0)))\n",
    "print(\"STD is : {}\".format(X_train.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472638a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4646a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean after scaling is : [-0.  0.  0. -0. -0.  0. -0.  0.]\n",
      "STD after scaling is : [1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"the mean after scaling is : {}\".format(X_train_scaled.mean(axis=0)))\n",
    "print(\"STD after scaling is : {}\".format(X_train_scaled.std(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c0a8a",
   "metadata": {},
   "source": [
    "<b>MinMax Scaler</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24113b4",
   "metadata": {},
   "source": [
    "It simply scale data between zero to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f21dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "m_scaler = MinMaxScaler()\n",
    "m_scaler.fit(X_train)\n",
    "X_train_m_scaled=m_scaler.transform(X_train)\n",
    "X_test_m_scaled=m_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f82a5835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean after scaling is : [0.23191401 0.54021318 0.03487142 0.02267722 0.03985452 0.00187521\n",
      " 0.32992917 0.47631967]\n",
      "STD after scaling is : [0.12948678 0.24702835 0.0182434  0.01413798 0.03163768 0.00913505\n",
      " 0.22796159 0.1996995 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"the mean after scaling is : {}\".format(X_train_m_scaled.mean(axis=0)))\n",
    "print(\"STD after scaling is : {}\".format(X_train_m_scaled.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ae8d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_m_scaled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7f50da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_m_scaled.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f79e6d",
   "metadata": {},
   "source": [
    "<b>Robust Scaler</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43de1f",
   "metadata": {},
   "source": [
    "Standard Scaler and MinMax Scaler use values like the mean, maximum and minimum values of the columns,which are sensitive to outliers.If our data has many outliers,they absoulutlly affect min,max or mean.So using two above method wouldn't garrantee a balanced data and a normal distribution after scaling. Robust Scaler is another method which is sensitive to outiers. This Mehod first removes the median from our data, then scales the data by the InterQuartile Range(IQR).\n",
    "IRQ is the difference between the first and third quartile of the variable:\n",
    "                                                \n",
    "                                                IQR = Q3 – Q1\n",
    "and the scaled value is :\n",
    "                                        x_scaled = (x – Q1)/(Q3 – Q1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd694a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "r_scaler = RobustScaler()\n",
    "r_scaler.fit(X_train)\n",
    "X_train_r_scaled=r_scaler.transform(X_train)\n",
    "X_test_r_scaled=r_scaler.transform(X_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
